<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Llama Core, abbreviated as `llama-core`, defines a set of APIs. Developers can utilize these APIs to build applications based on large models, such as chatbots, RAG, and more."><title>llama_core - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../static.files/rustdoc-46132b98.css"><meta name="rustdoc-vars" data-root-path="../" data-static-root-path="../static.files/" data-current-crate="llama_core" data-themes="" data-resource-suffix="" data-rustdoc-version="1.85.0-nightly (a224f3807 2024-12-09)" data-channel="nightly" data-search-js="search-92e6798f.js" data-settings-js="settings-0f613d39.js" ><script src="../static.files/storage-59e33391.js"></script><script defer src="../crates.js"></script><script defer src="../static.files/main-5f194d8c.js"></script><noscript><link rel="stylesheet" href="../static.files/noscript-893ab5e7.css"></noscript><link rel="alternate icon" type="image/png" href="../static.files/favicon-32x32-6580c154.png"><link rel="icon" type="image/svg+xml" href="../static.files/favicon-044be391.svg"></head><body class="rustdoc mod crate"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle" title="show sidebar"></button></nav><nav class="sidebar"><div class="sidebar-crate"><h2><a href="../llama_core/index.html">llama_<wbr>core</a><span class="version">0.24.1</span></h2></div><div class="sidebar-elems"><ul class="block"><li><a id="all-types" href="all.html">All Items</a></li></ul><section id="rustdoc-toc"><h3><a href="#reexports">Crate Items</a></h3><ul class="block"><li><a href="#reexports" title="Re-exports">Re-exports</a></li><li><a href="#modules" title="Modules">Modules</a></li><li><a href="#structs" title="Structs">Structs</a></li><li><a href="#enums" title="Enums">Enums</a></li><li><a href="#constants" title="Constants">Constants</a></li><li><a href="#functions" title="Functions">Functions</a></li></ul></section><div id="rustdoc-modnav"></div></div></nav><div class="sidebar-resizer"></div><main><div class="width-limiter"><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><h1>Crate <span>llama_core</span><button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><rustdoc-toolbar></rustdoc-toolbar><span class="sub-heading"><a class="src" href="../src/llama_core/lib.rs.html#1-1048">Source</a> </span></div><details class="toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><p>Llama Core, abbreviated as <code>llama-core</code>, defines a set of APIs. Developers can utilize these APIs to build applications based on large models, such as chatbots, RAG, and more.</p>
</div></details><h2 id="reexports" class="section-header">Re-exports<a href="#reexports" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name" id="reexport.LlamaCoreError"><code>pub use error::<a class="enum" href="error/enum.LlamaCoreError.html" title="enum llama_core::error::LlamaCoreError">LlamaCoreError</a>;</code></div></li><li><div class="item-name" id="reexport.EngineType"><code>pub use graph::<a class="enum" href="graph/enum.EngineType.html" title="enum llama_core::graph::EngineType">EngineType</a>;</code></div></li><li><div class="item-name" id="reexport.Graph"><code>pub use graph::<a class="struct" href="graph/struct.Graph.html" title="struct llama_core::graph::Graph">Graph</a>;</code></div></li><li><div class="item-name" id="reexport.GraphBuilder"><code>pub use graph::<a class="struct" href="graph/struct.GraphBuilder.html" title="struct llama_core::graph::GraphBuilder">GraphBuilder</a>;</code></div></li><li><div class="item-name" id="reexport.GgmlMetadata"><code>pub use metadata::ggml::<a class="struct" href="metadata/ggml/struct.GgmlMetadata.html" title="struct llama_core::metadata::ggml::GgmlMetadata">GgmlMetadata</a>;</code></div></li><li><div class="item-name" id="reexport.PiperMetadata"><code>pub use metadata::piper::<a class="struct" href="metadata/piper/struct.PiperMetadata.html" title="struct llama_core::metadata::piper::PiperMetadata">PiperMetadata</a>;</code></div></li><li><div class="item-name" id="reexport.BaseMetadata"><code>pub use metadata::<a class="trait" href="metadata/trait.BaseMetadata.html" title="trait llama_core::metadata::BaseMetadata">BaseMetadata</a>;</code></div></li></ul><h2 id="modules" class="section-header">Modules<a href="#modules" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name"><a class="mod" href="audio/index.html" title="mod llama_core::audio">audio</a></div><div class="desc docblock-short">Define APIs for audio generation, transcription, and translation.</div></li><li><div class="item-name"><a class="mod" href="chat/index.html" title="mod llama_core::chat">chat</a></div><div class="desc docblock-short">Define APIs for chat completion.</div></li><li><div class="item-name"><a class="mod" href="completions/index.html" title="mod llama_core::completions">completions</a></div><div class="desc docblock-short">Define APIs for completions.</div></li><li><div class="item-name"><a class="mod" href="embeddings/index.html" title="mod llama_core::embeddings">embeddings</a></div><div class="desc docblock-short">Define APIs for computing embeddings.</div></li><li><div class="item-name"><a class="mod" href="error/index.html" title="mod llama_core::error">error</a></div><div class="desc docblock-short">Error types for the Llama Core library.</div></li><li><div class="item-name"><a class="mod" href="files/index.html" title="mod llama_core::files">files</a></div><div class="desc docblock-short">Define APIs for file operations.</div></li><li><div class="item-name"><a class="mod" href="graph/index.html" title="mod llama_core::graph">graph</a></div><div class="desc docblock-short">Define Graph and GraphBuilder APIs for creating a new computation graph.</div></li><li><div class="item-name"><a class="mod" href="images/index.html" title="mod llama_core::images">images</a></div><div class="desc docblock-short">Define APIs for image generation and edit.</div></li><li><div class="item-name"><a class="mod" href="metadata/index.html" title="mod llama_core::metadata">metadata</a></div><div class="desc docblock-short">Define the types for model metadata.</div></li><li><div class="item-name"><a class="mod" href="models/index.html" title="mod llama_core::models">models</a></div><div class="desc docblock-short">Define APIs for querying models.</div></li><li><div class="item-name"><a class="mod" href="rag/index.html" title="mod llama_core::rag">rag</a><wbr><span class="stab portability" title="Available on crate feature `rag` only"><code>rag</code></span></div><div class="desc docblock-short">Define APIs for RAG operations.</div></li><li><div class="item-name"><a class="mod" href="search/index.html" title="mod llama_core::search">search</a><wbr><span class="stab portability" title="Available on crate feature `search` only"><code>search</code></span></div><div class="desc docblock-short">Define APIs for web search operations.</div></li><li><div class="item-name"><a class="mod" href="utils/index.html" title="mod llama_core::utils">utils</a></div><div class="desc docblock-short">Define utility functions.</div></li></ul><h2 id="structs" class="section-header">Structs<a href="#structs" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name"><a class="struct" href="struct.PluginInfo.html" title="struct llama_core::PluginInfo">Plugin<wbr>Info</a></div><div class="desc docblock-short">Version info of the <code>wasi-nn_ggml</code> plugin, including the build number and the commit id.</div></li></ul><h2 id="enums" class="section-header">Enums<a href="#enums" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name"><a class="enum" href="enum.RunningMode.html" title="enum llama_core::RunningMode">Running<wbr>Mode</a></div><div class="desc docblock-short">Running mode</div></li><li><div class="item-name"><a class="enum" href="enum.StableDiffusionTask.html" title="enum llama_core::StableDiffusionTask">Stable<wbr>Diffusion<wbr>Task</a></div><div class="desc docblock-short">The task type of the stable diffusion context</div></li></ul><h2 id="constants" class="section-header">Constants<a href="#constants" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name"><a class="constant" href="constant.ARCHIVES_DIR.html" title="constant llama_core::ARCHIVES_DIR">ARCHIVES_<wbr>DIR</a></div><div class="desc docblock-short">The directory for storing the archives in wasm virtual file system.</div></li></ul><h2 id="functions" class="section-header">Functions<a href="#functions" class="anchor">§</a></h2><ul class="item-table"><li><div class="item-name"><a class="fn" href="fn.get_plugin_info.html" title="fn llama_core::get_plugin_info">get_<wbr>plugin_<wbr>info</a></div><div class="desc docblock-short">Get the plugin info</div></li><li><div class="item-name"><a class="fn" href="fn.init_ggml_context.html" title="fn llama_core::init_ggml_context">init_<wbr>ggml_<wbr>context</a></div><div class="desc docblock-short">Initialize the ggml context</div></li><li><div class="item-name"><a class="fn" href="fn.init_ggml_rag_context.html" title="fn llama_core::init_ggml_rag_context">init_<wbr>ggml_<wbr>rag_<wbr>context</a><wbr><span class="stab portability" title="Available on crate feature `rag` only"><code>rag</code></span></div><div class="desc docblock-short">Initialize the ggml context for RAG scenarios.</div></li><li><div class="item-name"><a class="fn" href="fn.init_piper_context.html" title="fn llama_core::init_piper_context">init_<wbr>piper_<wbr>context</a></div><div class="desc docblock-short">Initialize the piper context</div></li><li><div class="item-name"><a class="fn" href="fn.init_sd_context_with_full_model.html" title="fn llama_core::init_sd_context_with_full_model">init_<wbr>sd_<wbr>context_<wbr>with_<wbr>full_<wbr>model</a></div><div class="desc docblock-short">Initialize the stable-diffusion context with the given full diffusion model</div></li><li><div class="item-name"><a class="fn" href="fn.init_sd_context_with_standalone_model.html" title="fn llama_core::init_sd_context_with_standalone_model">init_<wbr>sd_<wbr>context_<wbr>with_<wbr>standalone_<wbr>model</a></div><div class="desc docblock-short">Initialize the stable-diffusion context with the given standalone diffusion model</div></li><li><div class="item-name"><a class="fn" href="fn.init_whisper_context.html" title="fn llama_core::init_whisper_context">init_<wbr>whisper_<wbr>context</a><wbr><span class="stab portability" title="Available on crate feature `whisper` only"><code>whisper</code></span></div><div class="desc docblock-short">Initialize the whisper context</div></li><li><div class="item-name"><a class="fn" href="fn.running_mode.html" title="fn llama_core::running_mode">running_<wbr>mode</a></div><div class="desc docblock-short">Return the current running mode.</div></li></ul></section></div></main></body></html>